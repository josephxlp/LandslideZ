{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc17b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training resnet18 ========\n",
      "[resnet18] Epoch 1 Train F1: 0.7634 | Val F1: 0.7452\n",
      "[resnet18] Epoch 2 Train F1: 0.8190 | Val F1: 0.8273\n",
      "[resnet18] Epoch 3 Train F1: 0.8542 | Val F1: 0.8530\n",
      "[resnet18] Epoch 4 Train F1: 0.8571 | Val F1: 0.8950\n",
      "[resnet18] Epoch 5 Train F1: 0.8742 | Val F1: 0.8783\n",
      "[resnet18] Epoch 6 Train F1: 0.8792 | Val F1: 0.8994\n",
      "[resnet18] Epoch 7 Train F1: 0.8853 | Val F1: 0.9072\n",
      "[resnet18] Epoch 8 Train F1: 0.8994 | Val F1: 0.8956\n",
      "[resnet18] Epoch 9 Train F1: 0.9038 | Val F1: 0.8747\n",
      "[resnet18] Epoch 10 Train F1: 0.9059 | Val F1: 0.9070\n",
      "[resnet18] Epoch 11 Train F1: 0.9042 | Val F1: 0.8998\n",
      "[resnet18] Epoch 12 Train F1: 0.9134 | Val F1: 0.8970\n",
      "[resnet18] Epoch 13 Train F1: 0.9269 | Val F1: 0.9039\n",
      "[resnet18] Epoch 14 Train F1: 0.9287 | Val F1: 0.8922\n",
      "[resnet18] Epoch 15 Train F1: 0.9315 | Val F1: 0.8818\n",
      "[resnet18] Epoch 16 Train F1: 0.9377 | Val F1: 0.8996\n",
      "[resnet18] Epoch 17 Train F1: 0.8951 | Val F1: 0.9018\n",
      "[resnet18] Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet18_f1_0.9072: 100%|██████████| 338/338 [00:00<00:00, 373.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training resnet34 ========\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/tdx/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 114MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet34] Epoch 1 Train F1: 0.7509 | Val F1: 0.7468\n",
      "[resnet34] Epoch 2 Train F1: 0.7873 | Val F1: 0.8239\n",
      "[resnet34] Epoch 3 Train F1: 0.8538 | Val F1: 0.7788\n",
      "[resnet34] Epoch 4 Train F1: 0.8102 | Val F1: 0.7540\n",
      "[resnet34] Epoch 5 Train F1: 0.8476 | Val F1: 0.8461\n",
      "[resnet34] Epoch 6 Train F1: 0.8716 | Val F1: 0.8240\n",
      "[resnet34] Epoch 7 Train F1: 0.8723 | Val F1: 0.8887\n",
      "[resnet34] Epoch 8 Train F1: 0.8204 | Val F1: 0.8307\n",
      "[resnet34] Epoch 9 Train F1: 0.8585 | Val F1: 0.8815\n",
      "[resnet34] Epoch 10 Train F1: 0.8781 | Val F1: 0.8885\n",
      "[resnet34] Epoch 11 Train F1: 0.8827 | Val F1: 0.8855\n",
      "[resnet34] Epoch 12 Train F1: 0.8935 | Val F1: 0.6923\n",
      "[resnet34] Epoch 13 Train F1: 0.8924 | Val F1: 0.8998\n",
      "[resnet34] Epoch 14 Train F1: 0.9065 | Val F1: 0.9068\n",
      "[resnet34] Epoch 15 Train F1: 0.9031 | Val F1: 0.8903\n",
      "[resnet34] Epoch 16 Train F1: 0.8865 | Val F1: 0.8828\n",
      "[resnet34] Epoch 17 Train F1: 0.8863 | Val F1: 0.8979\n",
      "[resnet34] Epoch 18 Train F1: 0.9036 | Val F1: 0.9023\n",
      "[resnet34] Epoch 19 Train F1: 0.9203 | Val F1: 0.8987\n",
      "[resnet34] Epoch 20 Train F1: 0.9199 | Val F1: 0.9015\n",
      "[resnet34] Epoch 21 Train F1: 0.9317 | Val F1: 0.9077\n",
      "[resnet34] Epoch 22 Train F1: 0.9100 | Val F1: 0.8887\n",
      "[resnet34] Epoch 23 Train F1: 0.9227 | Val F1: 0.8987\n",
      "[resnet34] Epoch 24 Train F1: 0.9364 | Val F1: 0.9110\n",
      "[resnet34] Epoch 25 Train F1: 0.9385 | Val F1: 0.8951\n",
      "[resnet34] Epoch 26 Train F1: 0.9493 | Val F1: 0.9120\n",
      "[resnet34] Epoch 27 Train F1: 0.9601 | Val F1: 0.9061\n",
      "[resnet34] Epoch 28 Train F1: 0.9674 | Val F1: 0.9100\n",
      "[resnet34] Epoch 29 Train F1: 0.9070 | Val F1: 0.9054\n",
      "[resnet34] Epoch 30 Train F1: 0.9446 | Val F1: 0.9124\n",
      "[resnet34] Epoch 31 Train F1: 0.9640 | Val F1: 0.9104\n",
      "[resnet34] Epoch 32 Train F1: 0.9740 | Val F1: 0.9144\n",
      "[resnet34] Epoch 33 Train F1: 0.9802 | Val F1: 0.9120\n",
      "[resnet34] Epoch 34 Train F1: 0.9847 | Val F1: 0.8971\n",
      "[resnet34] Epoch 35 Train F1: 0.9766 | Val F1: 0.9028\n",
      "[resnet34] Epoch 36 Train F1: 0.9828 | Val F1: 0.9011\n",
      "[resnet34] Epoch 37 Train F1: 0.9907 | Val F1: 0.8949\n",
      "[resnet34] Epoch 38 Train F1: 0.9838 | Val F1: 0.8995\n",
      "[resnet34] Epoch 39 Train F1: 0.9904 | Val F1: 0.9005\n",
      "[resnet34] Epoch 40 Train F1: 0.9937 | Val F1: 0.8880\n",
      "[resnet34] Epoch 41 Train F1: 0.9948 | Val F1: 0.8979\n",
      "[resnet34] Epoch 42 Train F1: 0.9925 | Val F1: 0.8987\n",
      "[resnet34] Early stopping at epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet34_f1_0.9144: 100%|██████████| 338/338 [00:01<00:00, 327.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training resnet50 ========\n",
      "[resnet50] Epoch 1 Train F1: 0.7884 | Val F1: 0.8513\n",
      "[resnet50] Epoch 2 Train F1: 0.8540 | Val F1: 0.8706\n",
      "[resnet50] Epoch 3 Train F1: 0.8667 | Val F1: 0.8932\n",
      "[resnet50] Epoch 4 Train F1: 0.8761 | Val F1: 0.9056\n",
      "[resnet50] Epoch 5 Train F1: 0.9003 | Val F1: 0.8973\n",
      "[resnet50] Epoch 6 Train F1: 0.9047 | Val F1: 0.8709\n",
      "[resnet50] Epoch 7 Train F1: 0.9145 | Val F1: 0.8861\n",
      "[resnet50] Epoch 8 Train F1: 0.9195 | Val F1: 0.9036\n",
      "[resnet50] Epoch 9 Train F1: 0.9232 | Val F1: 0.9029\n",
      "[resnet50] Epoch 10 Train F1: 0.9342 | Val F1: 0.8959\n",
      "[resnet50] Epoch 11 Train F1: 0.9422 | Val F1: 0.9180\n",
      "[resnet50] Epoch 12 Train F1: 0.9363 | Val F1: 0.9013\n",
      "[resnet50] Epoch 13 Train F1: 0.9519 | Val F1: 0.9147\n",
      "[resnet50] Epoch 14 Train F1: 0.9487 | Val F1: 0.9073\n",
      "[resnet50] Epoch 15 Train F1: 0.9584 | Val F1: 0.9131\n",
      "[resnet50] Epoch 16 Train F1: 0.9682 | Val F1: 0.9050\n",
      "[resnet50] Epoch 17 Train F1: 0.9725 | Val F1: 0.9039\n",
      "[resnet50] Epoch 18 Train F1: 0.9687 | Val F1: 0.8951\n",
      "[resnet50] Epoch 19 Train F1: 0.9729 | Val F1: 0.9088\n",
      "[resnet50] Epoch 20 Train F1: 0.9774 | Val F1: 0.8902\n",
      "[resnet50] Epoch 21 Train F1: 0.9828 | Val F1: 0.9091\n",
      "[resnet50] Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet50_f1_0.9180: 100%|██████████| 338/338 [00:01<00:00, 270.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training resnet101 ========\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /home/tdx/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171M/171M [00:01<00:00, 115MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 1 Train F1: 0.7689 | Val F1: 0.7452\n",
      "[resnet101] Epoch 2 Train F1: 0.8382 | Val F1: 0.8899\n",
      "[resnet101] Epoch 3 Train F1: 0.8514 | Val F1: 0.8648\n",
      "[resnet101] Epoch 4 Train F1: 0.8534 | Val F1: 0.8659\n",
      "[resnet101] Epoch 5 Train F1: 0.8575 | Val F1: 0.8868\n",
      "[resnet101] Epoch 6 Train F1: 0.8741 | Val F1: 0.8879\n",
      "[resnet101] Epoch 7 Train F1: 0.8910 | Val F1: 0.8865\n",
      "[resnet101] Epoch 8 Train F1: 0.8955 | Val F1: 0.9118\n",
      "[resnet101] Epoch 9 Train F1: 0.8865 | Val F1: 0.8944\n",
      "[resnet101] Epoch 10 Train F1: 0.8922 | Val F1: 0.8876\n",
      "[resnet101] Epoch 11 Train F1: 0.8680 | Val F1: 0.7897\n",
      "[resnet101] Epoch 12 Train F1: 0.8854 | Val F1: 0.9038\n",
      "[resnet101] Epoch 13 Train F1: 0.8829 | Val F1: 0.8755\n",
      "[resnet101] Epoch 14 Train F1: 0.9010 | Val F1: 0.8980\n",
      "[resnet101] Epoch 15 Train F1: 0.9147 | Val F1: 0.9167\n",
      "[resnet101] Epoch 16 Train F1: 0.9166 | Val F1: 0.8822\n",
      "[resnet101] Epoch 17 Train F1: 0.9233 | Val F1: 0.9153\n",
      "[resnet101] Epoch 18 Train F1: 0.9325 | Val F1: 0.8916\n",
      "[resnet101] Epoch 19 Train F1: 0.9375 | Val F1: 0.8897\n",
      "[resnet101] Epoch 20 Train F1: 0.9379 | Val F1: 0.9127\n",
      "[resnet101] Epoch 21 Train F1: 0.9441 | Val F1: 0.9057\n",
      "[resnet101] Epoch 22 Train F1: 0.9531 | Val F1: 0.8986\n",
      "[resnet101] Epoch 23 Train F1: 0.9585 | Val F1: 0.9105\n",
      "[resnet101] Epoch 24 Train F1: 0.9619 | Val F1: 0.8740\n",
      "[resnet101] Epoch 25 Train F1: 0.9690 | Val F1: 0.8956\n",
      "[resnet101] Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet101_f1_0.9167: 100%|██████████| 338/338 [00:01<00:00, 190.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training resnet152 ========\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to /home/tdx/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230M/230M [00:02<00:00, 116MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet152] Epoch 1 Train F1: 0.7701 | Val F1: 0.8192\n",
      "[resnet152] Epoch 2 Train F1: 0.8371 | Val F1: 0.8639\n",
      "[resnet152] Epoch 3 Train F1: 0.8679 | Val F1: 0.8646\n",
      "[resnet152] Epoch 4 Train F1: 0.8661 | Val F1: 0.8285\n",
      "[resnet152] Epoch 5 Train F1: 0.8609 | Val F1: 0.8091\n",
      "[resnet152] Epoch 6 Train F1: 0.8164 | Val F1: 0.7452\n",
      "[resnet152] Epoch 7 Train F1: 0.7472 | Val F1: 0.8093\n",
      "[resnet152] Epoch 8 Train F1: 0.8202 | Val F1: 0.8500\n",
      "[resnet152] Epoch 9 Train F1: 0.8521 | Val F1: 0.8121\n",
      "[resnet152] Epoch 10 Train F1: 0.8596 | Val F1: 0.8454\n",
      "[resnet152] Epoch 11 Train F1: 0.8356 | Val F1: 0.8795\n",
      "[resnet152] Epoch 12 Train F1: 0.8645 | Val F1: 0.8827\n",
      "[resnet152] Epoch 13 Train F1: 0.8765 | Val F1: 0.8985\n",
      "[resnet152] Epoch 14 Train F1: 0.8905 | Val F1: 0.8752\n",
      "[resnet152] Epoch 15 Train F1: 0.8914 | Val F1: 0.7761\n",
      "[resnet152] Epoch 16 Train F1: 0.8815 | Val F1: 0.8649\n",
      "[resnet152] Epoch 17 Train F1: 0.8889 | Val F1: 0.8768\n",
      "[resnet152] Epoch 18 Train F1: 0.8898 | Val F1: 0.8319\n",
      "[resnet152] Epoch 19 Train F1: 0.8755 | Val F1: 0.8648\n",
      "[resnet152] Epoch 20 Train F1: 0.8618 | Val F1: 0.8531\n",
      "[resnet152] Epoch 21 Train F1: 0.8833 | Val F1: 0.8862\n",
      "[resnet152] Epoch 22 Train F1: 0.8901 | Val F1: 0.8927\n",
      "[resnet152] Epoch 23 Train F1: 0.8669 | Val F1: 0.9080\n",
      "[resnet152] Epoch 24 Train F1: 0.8987 | Val F1: 0.8760\n",
      "[resnet152] Epoch 25 Train F1: 0.8918 | Val F1: 0.8932\n",
      "[resnet152] Epoch 26 Train F1: 0.9043 | Val F1: 0.9118\n",
      "[resnet152] Epoch 27 Train F1: 0.9141 | Val F1: 0.9056\n",
      "[resnet152] Epoch 28 Train F1: 0.9246 | Val F1: 0.8831\n",
      "[resnet152] Epoch 29 Train F1: 0.9278 | Val F1: 0.9177\n",
      "[resnet152] Epoch 30 Train F1: 0.9347 | Val F1: 0.8808\n",
      "[resnet152] Epoch 31 Train F1: 0.9326 | Val F1: 0.8486\n",
      "[resnet152] Epoch 32 Train F1: 0.8502 | Val F1: 0.8988\n",
      "[resnet152] Epoch 33 Train F1: 0.8891 | Val F1: 0.9098\n",
      "[resnet152] Epoch 34 Train F1: 0.9042 | Val F1: 0.9124\n",
      "[resnet152] Epoch 35 Train F1: 0.9246 | Val F1: 0.8856\n",
      "[resnet152] Epoch 36 Train F1: 0.9252 | Val F1: 0.9043\n",
      "[resnet152] Epoch 37 Train F1: 0.9351 | Val F1: 0.8834\n",
      "[resnet152] Epoch 38 Train F1: 0.9446 | Val F1: 0.9002\n",
      "[resnet152] Epoch 39 Train F1: 0.9478 | Val F1: 0.9026\n",
      "[resnet152] Early stopping at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_f1_0.9177: 100%|██████████| 338/338 [00:02<00:00, 145.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Training densenet121 ========\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/tdx/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 106MB/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 12, 64, 64] to have 3 channels, but got 12 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[32m    154\u001b[39m model = constructor()\n\u001b[32m    155\u001b[39m model = wrap_model(model)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m model, f1 = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m predict_and_save(model, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_f1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, model_name)\u001b[39m\n\u001b[32m     87\u001b[39m x, y = x.to(device), y.to(device)\n\u001b[32m     88\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m loss = criterion(out, y)\n\u001b[32m     91\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torchvision/models/densenet.py:213\u001b[39m, in \u001b[36mDenseNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m     out = F.relu(features, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    215\u001b[39m     out = F.adaptive_avg_pool2d(out, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/geodl/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 12, 64, 64] to have 3 channels, but got 12 channels instead"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load CSV and define paths ===\n",
    "train_dir = \"data/train_data\"\n",
    "test_dir = \"data/test_data\"\n",
    "train_df = pd.read_csv('data/Train.csv')\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "train_df['ID_path'] = train_df['ID'].apply(lambda x: os.path.join(train_dir, f\"{x}.npy\"))\n",
    "test_df['ID_path'] = test_df['ID'].apply(lambda x: os.path.join(test_dir, f\"{x}.npy\"))\n",
    "\n",
    "# === Train/Validation Split ===\n",
    "train_set, valid_set = train_test_split(train_df, stratify=train_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# === Data Utilities ===\n",
    "def load_and_normalize_npy_image(path):\n",
    "    img = np.load(path).astype(np.float32)\n",
    "    img = (img - img.min((0, 1))) / (img.max((0, 1)) - img.min((0, 1)) + 1e-5)\n",
    "    return img\n",
    "\n",
    "class NPYDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = load_and_normalize_npy_image(self.df.iloc[idx]['ID_path'])\n",
    "        label = self.df.iloc[idx].get('label', -1)\n",
    "        img = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = load_and_normalize_npy_image(self.df.iloc[idx]['ID_path'])\n",
    "        img = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "        return img, self.df.iloc[idx]['ID']\n",
    "\n",
    "# === Model Wrapping Utility ===\n",
    "def wrap_model(model, in_channels=12, num_classes=2):\n",
    "    if hasattr(model, 'conv1') and isinstance(model.conv1, nn.Conv2d):\n",
    "        model.conv1 = nn.Conv2d(in_channels, model.conv1.out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    if hasattr(model, 'classifier') and isinstance(model.classifier, nn.Linear):\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# === Training ===\n",
    "def train_model(model, model_name):\n",
    "    train_loader = DataLoader(NPYDataset(train_set), batch_size=16, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(NPYDataset(valid_set), batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_val_f1, best_weights = 0, None\n",
    "    patience, counter = 10, 0\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        preds, labels = [], []\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds.extend(torch.argmax(out, 1).cpu().numpy())\n",
    "            labels.extend(y.cpu().numpy())\n",
    "        train_f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "        model.eval()\n",
    "        preds, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                preds.extend(torch.argmax(out, 1).cpu().numpy())\n",
    "                labels.extend(y.cpu().numpy())\n",
    "        val_f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "        print(f\"[{model_name}] Epoch {epoch+1} Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_weights = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    torch.save(model.state_dict(), f\"{model_name}_best_{best_val_f1:.4f}.pth\")\n",
    "    return model, best_val_f1\n",
    "\n",
    "# === Inference ===\n",
    "def predict_and_save(model, name):\n",
    "    loader = DataLoader(TestDataset(test_df), batch_size=16, shuffle=False, num_workers=4)\n",
    "    model.eval()\n",
    "    preds, ids = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, id_batch in tqdm(loader, desc=name):\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            preds.extend(torch.argmax(out, 1).cpu().numpy())\n",
    "            ids.extend(id_batch)\n",
    "\n",
    "    df = pd.DataFrame({'ID': ids, 'Predicted': preds})\n",
    "    os.makedirs(\"subs\", exist_ok=True)\n",
    "    df.to_csv(f\"subs/{name}_submission.csv\", index=False)\n",
    "\n",
    "# === Define Model Constructors ===\n",
    "model_names = {\n",
    "    'resnet18': lambda: models.resnet18(weights=models.ResNet18_Weights.DEFAULT),\n",
    "    'resnet34': lambda: models.resnet34(weights=models.ResNet34_Weights.DEFAULT),\n",
    "    'resnet50': lambda: models.resnet50(weights=models.ResNet50_Weights.DEFAULT),\n",
    "    'resnet101': lambda: models.resnet101(weights=models.ResNet101_Weights.DEFAULT),\n",
    "    'resnet152': lambda: models.resnet152(weights=models.ResNet152_Weights.DEFAULT),\n",
    "    'densenet121': lambda: models.densenet121(weights=models.DenseNet121_Weights.DEFAULT),\n",
    "    'efficientnet_b0': lambda: create_model('efficientnet_b0', pretrained=True, in_chans=12, num_classes=2),\n",
    "    'convnext_base': lambda: create_model('convnext_base', pretrained=True, in_chans=12, num_classes=2),\n",
    "    'swin_base_patch4_window7_224': lambda: create_model('swin_base_patch4_window7_224', pretrained=True, in_chans=12, num_classes=2)\n",
    "}\n",
    "\n",
    "# === Train & Predict Loop ===\n",
    "for name, constructor in model_names.items():\n",
    "    print(f\"\\n======== Training {name} ========\")\n",
    "    model = constructor()\n",
    "    model = wrap_model(model)\n",
    "    model, f1 = train_model(model, name)\n",
    "    predict_and_save(model, f\"{name}_f1_{f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffce0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
